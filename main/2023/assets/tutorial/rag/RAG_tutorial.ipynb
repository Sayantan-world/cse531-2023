{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Zero-shot Retrieval-Augmented Generation (RAG) Using Langchain and ChromaDB\n",
        "\n",
        "Welcome to this tutorial on Retrieval-Augmented Generation (RAG), a transformative approach in the field of natural language processing that combines the power of language models with the vast knowledge stored in external databases. In this tutorial, we will delve into the fundamentals of RAG, utilizing Langchain and ChromaDB, that facilitate seamless integration of external knowledge sources into language models.\n",
        "\n",
        "### What is RAG?\n",
        "Retrieval-Augmented Generation is a technique that enhances the capabilities of language models by allowing them to retrieve and utilize information from external databases. This method not only expands the model's knowledge base beyond its training data but also enables the generation of more accurate, relevant, and contextually rich responses.\n",
        "\n",
        "### Langchain\n",
        "Langchain, a versatile library, plays a crucial role in our RAG implementation. It provides an intuitive framework for integrating language models with various external data sources.\n",
        "\n",
        "### ChromaDB\n",
        "ChromaDB stands at the core of our retrieval system. It is a comprehensive, structured database that serves as the external knowledge repository for our RAG model.\n",
        "\n",
        "### Practical Application: QnA on a Story \"Slay the Spire\"\n",
        "To demonstrate the capabilities of RAG using Langchain and ChromaDB, we will embark on a unique project: creating a QnA model on a short story inspired by the game \"Slay the Spire.\"\n",
        "\n",
        "### Sources\n",
        "Some other sources to read more on how to implement RAG:\n",
        "1. https://haystack.deepset.ai/tutorials/07_rag_generator\n",
        "2. https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode\n",
        "3. https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
        "4. https://python.langchain.com/docs/expression_language/cookbook/retrieval\n",
        "5. https://python.langchain.com/docs/expression_language/cookbook/prompt_llm_parser\n",
        "\n"
      ],
      "metadata": {
        "id": "K2GzOIMHRJQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup the environment"
      ],
      "metadata": {
        "id": "OPDqFTaMUPvS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0U5bXQ_V5pU"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate langchain==0.0.263 tiktoken huggingface_hub sentence_transformers chromadb==0.4.5 openai==0.27.8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import all libs"
      ],
      "metadata": {
        "id": "T8NS_Z7vU51r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, TokenTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "ZJgjbv2nU4G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read HuggingFace Token\n",
        "\n",
        "Make sure to create a HuggingFace account.\n",
        "\n",
        "You can find your token here: https://huggingface.co/settings/tokens"
      ],
      "metadata": {
        "id": "zjd6s2g-UULv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read the file and store the token in the variable `hf_token`.\n",
        "try:\n",
        "    with open(\"./hf_token.txt\", \"r\") as file:\n",
        "        hf_token = file.readline().strip()\n",
        "    success = True\n",
        "except FileNotFoundError:\n",
        "    hf_token = \"\"\n",
        "    success = False\n",
        "\n",
        "success"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XYmMtGyFAjv",
        "outputId": "86e2cd05-0374-406c-82f6-1fec459710ac"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = hf_token"
      ],
      "metadata": {
        "id": "-vjawhd1WDX2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data using TextLoader\n",
        "\n",
        "Read More: https://python.langchain.com/docs/modules/data_connection/document_transformers/"
      ],
      "metadata": {
        "id": "5bP3BX4KVBdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"./story.txt\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "5FsVTCrqFXzn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "z30_AGhpF8Ft",
        "outputId": "2af332b7-7a7f-40e3-8827-f9686979b1de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In the mystical world of Slay the Spire, four adventurers embarked on a perilous journey to conquer the ever-changing spire.\\n\\nIronclad, a former soldier, possessed the power of strength and healing. His strikes were mighty, and his ability to recover health with each enemy defeated made him a formidable foe. The whispers of his past haunted him, driving his relentless pursuit to reach the spire's summit.\\n\\nSilent, a deadly huntress, excelled in agility and poison. Her quick strikes and ability to apply deadly toxins to her blades made her a master of prolonged battles. Silent, with her mysterious past, sought answers that she believed lay at the top of the spire.\\n\\nDefect, a rogue automaton, wielded the power of orbs. These orbs, orbiting around him, granted various abilities - lightning for damage, frost for defense, and plasma for energy. Defect's journey was one of self-discovery, seeking to understand its existence beyond its initial programming.\\n\\nWatcher, a monk from a distant land, had the unique ability to shift stances. Calm stance prepared her for future onslaughts, while Wrath doubled her attack power at the risk of receiving more damage. Her spiritual quest for enlightenment was intertwined with the spire's mysteries.\\n\\nTheir journey was fraught with dangers, battles, and alliances. Each character's unique abilities complemented the others, creating a formidable team. Yet, their personal quests and the allure of the spire's apex often led to conflicts and hard decisions. The deeper they ventured, the more they unraveled about themselves and the true nature of the spire.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the data loaded, we want to make chunks out of it. We will use the RecursiveCharacterSplitter and set overlapping window of 50 characters."
      ],
      "metadata": {
        "id": "yGWLSJ0SVzIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \"]\n",
        ")"
      ],
      "metadata": {
        "id": "BxYMlm_EHZu5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paras = r_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "8UlbbVQiHZw_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(paras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v5yNUV0HZzG",
        "outputId": "0c2b540c-919e-40f1-a3da-305ceb4c8399"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take a look at the chunks"
      ],
      "metadata": {
        "id": "_ryt3tH4WFeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for para in paras:\n",
        "    pprint(para.page_content)\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPQnekE_HZ1a",
        "outputId": "1258f83e-08d0-4299-fda3-1641ec359359"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('In the mystical world of Slay the Spire, four adventurers embarked on a '\n",
            " 'perilous journey to conquer the ever-changing spire.')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('Ironclad, a former soldier, possessed the power of strength and healing. His '\n",
            " 'strikes were mighty, and his ability to recover health with each enemy '\n",
            " 'defeated made him a formidable foe. The whispers of')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('made him a formidable foe. The whispers of his past haunted him, driving his '\n",
            " \"relentless pursuit to reach the spire's summit.\")\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('Silent, a deadly huntress, excelled in agility and poison. Her quick strikes '\n",
            " 'and ability to apply deadly toxins to her blades made her a master of '\n",
            " 'prolonged battles. Silent, with her mysterious past,')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('battles. Silent, with her mysterious past, sought answers that she believed '\n",
            " 'lay at the top of the spire.')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('Defect, a rogue automaton, wielded the power of orbs. These orbs, orbiting '\n",
            " 'around him, granted various abilities - lightning for damage, frost for '\n",
            " \"defense, and plasma for energy. Defect's journey was\")\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(\"and plasma for energy. Defect's journey was one of self-discovery, seeking \"\n",
            " 'to understand its existence beyond its initial programming.')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('Watcher, a monk from a distant land, had the unique ability to shift '\n",
            " 'stances. Calm stance prepared her for future onslaughts, while Wrath doubled '\n",
            " 'her attack power at the risk of receiving more')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('her attack power at the risk of receiving more damage. Her spiritual quest '\n",
            " \"for enlightenment was intertwined with the spire's mysteries.\")\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('Their journey was fraught with dangers, battles, and alliances. Each '\n",
            " \"character's unique abilities complemented the others, creating a formidable \"\n",
            " 'team. Yet, their personal quests and the allure of the')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(\"Yet, their personal quests and the allure of the spire's apex often led to \"\n",
            " 'conflicts and hard decisions. The deeper they ventured, the more they '\n",
            " 'unraveled about themselves and the true nature of the')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "'about themselves and the true nature of the spire.'\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will load the HF Embeddings"
      ],
      "metadata": {
        "id": "BmBEha7zWUh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings\n",
        "embeddings_model = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "6yadOhJiHZ3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persistent_directory = './chroma_db'"
      ],
      "metadata": {
        "id": "tUi93fbsI88C"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to disk\n",
        "\n",
        "Learn more: https://python.langchain.com/docs/integrations/vectorstores/chroma"
      ],
      "metadata": {
        "id": "d0AmS6-EKw2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "7xzYnjjpNkBr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents = paras,\n",
        "    embedding=embeddings_model,\n",
        "    persist_directory=persistent_directory,\n",
        ")"
      ],
      "metadata": {
        "id": "D1dYxdogI8-c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets retrieve top 3 chunks given a query"
      ],
      "metadata": {
        "id": "gTJB00apWbyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the Ironclad's unique ability?\"\n",
        "docs = vectordb.similarity_search(query, k=3)\n",
        "for rank, doc in enumerate(docs):\n",
        "    print(f\"Rank {rank+1}:\")\n",
        "    pprint(doc.page_content)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v83VhPTQI9Am",
        "outputId": "60fb9068-42ac-4e30-d28e-a081e997e578"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 1:\n",
            "('Ironclad, a former soldier, possessed the power of strength and healing. His '\n",
            " 'strikes were mighty, and his ability to recover health with each enemy '\n",
            " 'defeated made him a formidable foe. The whispers of')\n",
            "\n",
            "\n",
            "Rank 2:\n",
            "('Defect, a rogue automaton, wielded the power of orbs. These orbs, orbiting '\n",
            " 'around him, granted various abilities - lightning for damage, frost for '\n",
            " \"defense, and plasma for energy. Defect's journey was\")\n",
            "\n",
            "\n",
            "Rank 3:\n",
            "('her attack power at the risk of receiving more damage. Her spiritual quest '\n",
            " \"for enlightenment was intertwined with the spire's mysteries.\")\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the Rank 1 document/chunk contains the answer, but we cannot provide this chunk as the answer. We need to extract/ generate the answer from this chunk. Thus we use a LM/LLM to generate the answer given the chunk as the context.\n",
        "\n",
        "We will be using OpenAI GPT 3.5 Turbo, you can also use a free model from HF."
      ],
      "metadata": {
        "id": "zacpUXL7Wh_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read the file and store the token in the variable `open_ai_key`.\n",
        "try:\n",
        "    with open(\"./open-ai-key.txt\", \"r\") as file:\n",
        "        open_ai_key = file.readline().strip()\n",
        "    success = True\n",
        "except FileNotFoundError:\n",
        "    open_ai_key = \"\"\n",
        "    success = False\n",
        "\n",
        "success"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7nx9wEJPSyO",
        "outputId": "fd8d527c-a06c-4548-afe6-5d10843ef320"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=open_ai_key)"
      ],
      "metadata": {
        "id": "TnC2hCDII9Cq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we provide a template to the LLM, which contains the context(top chunk) and the query. It needs to generate the answer."
      ],
      "metadata": {
        "id": "RR1L2loqXTUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(query):\n",
        "    new_line = '\\n'\n",
        "    template = f\"Use the following pieces of context to answer truthfully.{new_line}If the context does not provide the truthful answer, make the answer as truthful as possible.{new_line}Use 15 words maximum. Keep the response as concise as possible.{new_line}{{context}}{new_line}Question: {{question}}{new_line}Response: \"\n",
        "    QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
        "\n",
        "    # Run chain\n",
        "    from langchain.chains import RetrievalQA\n",
        "\n",
        "    question = query\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm,\n",
        "                                          retriever=vectordb.as_retriever(),\n",
        "                                          return_source_documents=True,\n",
        "                                          chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "\n",
        "\n",
        "    result = qa_chain({\"query\": question})\n",
        "    return result[\"result\"]"
      ],
      "metadata": {
        "id": "Y85UXGLmXtM8"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Question:\", query)\n",
        "print(\"Answer:\",result[\"result\"].strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u01_kWGhPRxC",
        "outputId": "37cef6fc-fb6d-478a-b429-a6c8dbaafa62"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the Ironclad's unique ability?\n",
            "Answer: Strength and healing with each enemy defeated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How does the Silent use her skills in battle?\"\n",
        "result = get_answer(query)\n",
        "print(\"Question:\", query)\n",
        "print(\"Answer:\",result.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH0wsA2XPRzQ",
        "outputId": "121fb4c7-8608-47a8-872e-30a3c26e3259"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the Silent use her skills in battle?\n",
            "Answer: Silent uses agility and poison to quickly strike and apply toxins to her blades for prolonged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the types of orbs used by Defect and their functions?\"\n",
        "result = get_answer(query)\n",
        "print(\"Question:\", query)\n",
        "print(\"Answer:\",result.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlc9ioE_PR1l",
        "outputId": "4cce2882-7b71-45db-954f-a32bd453f420"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the types of orbs used by Defect and their functions?\n",
            "Answer: Lightning (damage), Frost (defense), Plasma (energy).\n"
          ]
        }
      ]
    }
  ]
}